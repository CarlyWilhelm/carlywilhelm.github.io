---
layout: post
title: "Commodification of Productivity, Attention, and the Digital Self"
---

To me, this week’s readings tied together several threads of conversation and discussion that have been initiated throughout the semester. I felt like it may be most useful to explicitly mention the ways that productivity, attention, technology has become commodified in the pieces we’ve read.  

In [“The Attention Economy: The Natural Economy of the Net”] (https://people.well.com/user/mgoldh/natecnet.html), Golhaber mentions, “Thus, in the new economy attention itself is property”. He argues that the power to gain, maintain, and direct someone’s attention will soon be more important than money itself. 

In [“The Productivity Obsession”](https://www.theatlantic.com/business/archive/2015/11/be-more-productive/415821/), Gregg writes on how productivity itself is becoming commodified. The author mentions a plethora of apps can be downloaded to help users manage time and continue to be productive. Employees must “wear” productivity as a badge of honor; it’s a mandatory quality of most workforces. 

Lastly, in [“The Binge Breaker”] (https://www.theatlantic.com/magazine/archive/2016/11/the-binge-breaker/501122/), Bosker and Harris discuss the ways in which certain technologies are fine-tuned to hold your attention for as long as possible. When these app and services are free, the resounding notion is that the users are the product. 

While these three ideas may seem disconnected, they are all pertinent in creating an environment where constant technology use is the norm—for work or “leisure”. This leads me to question who exactly is creating this environment and the social norms that come along with it. Of course, users have a role in limiting their own use. This was made evident by Thurston’s efforts to “unplug” for a month. However, in Bosker’s article, Harris alludes to a different idea. He explains, “Never before in history have the decisions of a handful of designers (mostly men, white, living in SF, aged 25–35) working at 3 companies”—Google, Apple, and Facebook—“had so much impact on how millions of people around the world spend their attention … We should feel an enormous responsibility to get this right.” This takes the power, blame, and responsibility away from the user, and places it in another groups’ hands. This group, as Harris mentions, is a fairly small demographic: white males in SF ages 25-25. Similarly, in Michelle Moravec’s [“The Endless Night of Wikipedia’s Notable Woman Problem”] (https://www.boundary2.org/2018/08/moravec/), she writes that most editors of Wikipedia are white, middle aged males. Of course, this is not to say that white males are the only players in the digital world. However, with a small demographic of people controlling what information we receive (creating content), and how we receive it (creating apps the content lives on), the ethical implications can’t be ignored.

So, what are we to do about this? Perhaps it involves Harris’s Time Well Spent Certification. Maybe more people should be mindful about their phone use, like Thurston. Should more teachers should make students undergo “No Digital Day”? Should schools go even further and mandate students to take a course on digital ethics? What are digital ethics? These questions and possibilities can go on forever—there are no easy answers. To end on a positive note, the future isn’t necessary bleak. As evidenced by the readings, these ideas have begun to garner conversations. Writers, designers, and even the public have started to see the potential ethical implications of the attention economy and this acknowledgment is the first step towards forward change. 
